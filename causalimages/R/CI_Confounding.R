#' Perform causal estimation under image confounding
#'
#' @param obsW A numeric vector where `0`'s correspond to control units and `1`'s to treated units.
#' @param obsY A numeric vector containing observed outcomes.
#' @param imageKeysOfUnits A vector of length `length(obsY)` specifying the unique image ID associated with each unit. Samples of `imageKeysOfUnits` are fed into the package to call images into memory.
#' @param file Path to a tfrecord file generated by `WriteTfRecord`.
#' @param conda_env A `conda` environment where computational environment lives, usually created via `causalimages::BuildBackend()`. Default = `"CausalImagesEnv"`.
#' @param conda_env_required A Boolean stating whether use of the specified conda environment is required.
#' @param X An optional numeric matrix containing tabular information used if `orthogonalize = T`. `X` is normalized internally and salience maps with respect to `X` are transformed back to the original scale.
#' @param long,lat Optional vectors specifying longitude and latitude coordinates for units. Used only for describing highest and lowest probability neighborhood units if specified.
#' @param transportabilityMat Optional matrix with a column named `imageKeysOfUnits` specifying keys to be used by the package for generating treatment effect predictions for out-of-sample points.
#' @param figuresTag A string specifying an identifier that is appended to all figure names.
#' @param figuresPath A string specifying file path for saved figures made in the analysis.
#' @param plotBands An integer or vector specifying which band position (from the image representation) should be plotted in the visual results. If a vector, `plotBands` should have 3 (and only 3) dimensions (corresponding to the 3 dimensions to be used in RGB plotting).
#' @param nSGD Number of stochastic gradient descent (SGD) iterations. Default = `400L`
#' @param nBoot Number of bootstrap iterations for uncertainty estimation.
#' @param batchSize Batch size used in SGD optimization. Default = `50L`.
#' @param useTrainingPertubations Boolean specifying whether to randomly perturb the image axes during training to reduce overfitting.
#' @param optimizeImageRep Boolean specifying whether to optimize over the image model representation (or only over downstream parameters).
#' @param dropoutRate Dropout rate used in training to prevent overfitting (`dropoutRate = 0` corresponds to no dropout).
#' @param droppathRate Droppath rate used in training to prevent overfitting (`droppathRate = 0` corresponds to no droppath).
#' @param testFrac Default = `0.1`. Fraction of observations held out as a test set to evaluate out-of-sample loss values.
#' @param strides (default = `2L`) Integer specifying the strides used in the convolutional layers.
#' @param plotResults (default = `T`) Should analysis results be plotted?
#' @param dataType (default = `"image"`) String specifying whether to assume `"image"` or `"video"` data types.
#' @param nWidth_ImageRep Integer specifying width of image model representation.
#' @param nDepth_ImageRep Integer specifying depth of image model representation.
#' @param nWidth_Dense Integer specifying width of image model representation.
#' @param nDepth_Dense Integer specifying depth of dense model representation.
#' @param kernelSize Dimensions used in spatial convolutions.
#' @param TfRecords_BufferScaler The buffer size used in `tfrecords` mode is `batchSize*TfRecords_BufferScaler`. Lower `TfRecords_BufferScaler` towards 1 if out-of-memory problems.
#'
#' @return Returns a list consisting of
#' \itemize{
#'   \item `ATE_est` ATE estimate.
#'   \item `ATE_se` Standard error estimate for the ATE.
#'   \item `plotResults` If set to `TRUE`, causal salience plots are saved to disk, characterizing the image confounding structure. See references for details.
#' }
#'
#' @section References:
#' \itemize{
#' \item  Connor T. Jerzak, Fredrik Johansson, Adel Daoud. Integrating Earth Observation Data into Causal Inference: Challenges and Opportunities. *ArXiv Preprint*, 2023.
#' }
#'
#' @examples
#' # For a tutorial, see
#' # github.com/cjerzak/causalimages-software/
#'
#' @export
#' @md

AnalyzeImageConfounding <- function(
                                   obsW,
                                   obsY,
                                   X = NULL,
                                   file = NULL,
                                   imageKeysOfUnits = NULL,
                                   fileTransport = NULL,
                                   imageKeysOfUnitsTransport = NULL,
                                   nBoot = 10L,
                                   inputAvePoolingSize = 1L,
                                   useTrainingPertubations = T,
                                   useScalePertubations = F,
                                   
                                   crossFit = FALSE, 
                                   augmented = FALSE,

                                   orthogonalize = F,
                                   transportabilityMat = NULL,
                                   latTransport = NULL,
                                   longTransport = NULL,
                                   lat = NULL,
                                   long = NULL,
                                   conda_env = "CausalImagesEnv",
                                   conda_env_required = T,
                                   Sys.setenv_text = NULL,

                                   figuresTag = NULL,
                                   figuresPath = "./",
                                   plotBands = 1L,
                                   plotResults = T,

                                   XCrossModal = T, 
                                   XForceModal = F, 
                                   optimizeImageRep = T,
                                   nonLinearScaler = NULL,
                                   nWidth_ImageRep = 64L,  nDepth_ImageRep = 1L, kernelSize = 5L,
                                   nWidth_Dense = 64L,  nDepth_Dense = 1L,
                                   imageModelClass = "VisionTransformer",
                                   pretrainedModel = NULL, 

                                   strides = 2L,
                                   nDepth_TemporalRep = 3L,
                                   patchEmbedDim = 16L,
                                   dropoutRate = 0.1,
                                   droppathRate = 0.1,
                                   batchSize = 16L,
                                   nSGD  = 400L,
                                   earlyStopThreshold = NULL,
                                   testFrac = 0.05,
                                   TfRecords_BufferScaler = 4L,
                                   learningRateMax = 0.001,
                                   TFRecordControl = NULL, 
                                   dataType = "image",
                                   image_dtype = "float16",
                                   atError = "stop", # stop or debug
                                   seed = NULL){
  {
    if(!"jax" %in% ls(envir = cienv)) {
      initialize_jax(conda_env = conda_env, 
                     conda_env_required = conda_env_required,
                     Sys.setenv_text = Sys.setenv_text) 
    }
    message2(sprintf("Default device: %s",cienv$jnp$array(0.)$devices()))

    # set float type
    library( tensorflow );
    if((image_dtype_char <- image_dtype) == "float16"){  image_dtype_tf <- cienv$tf$float16; ComputeDtype <- image_dtype <- cienv$jnp$float16 }
    if(image_dtype_char == "bfloat16"){  image_dtype_tf <- cienv$tf$bfloat16; ComputeDtype <- image_dtype <- cienv$jnp$bfloat16 }
    if(is.null(seed)){ seed <- ai(runif(1,1,10000)) }
    obsW <- f2n(obsW); obsY <- f2n(obsY)
    
    # set memory growth for tensorflow 
    for(device_ in cienv$tf$config$list_physical_devices()){
       try(cienv$tf$config$experimental$set_memory_growth(device_, T),T)
    }
  }

  message2("Setting input types in AnalyzeImageConfounding()...") 
  if(!is.null(pretrainedModel)){ pretrainedModel <- as.character(pretrainedModel) } 
  if(!is.null(optimizeImageRep)){ optimizeImageRep <- as.logical(as.character(optimizeImageRep)) }
  if(!is.null(imageModelClass)){ imageModelClass <- as.character(imageModelClass) }
  if(!is.null(nWidth_ImageRep)){ nWidth_ImageRep <- as.integer(f2n(nWidth_ImageRep)) }
  
  # figure name info 
  FigNameAppend <- sprintf("KW%s_InputAvePool%s_OptimizeImageRep%s_Tag%s",
                           kernelSize, inputAvePoolingSize,
                           optimizeImageRep, figuresTag)
  tagInFigures <- !is.null(figuresTag)
  figuresTag <- ifelse(is.null(figuresTag), yes = "", no = figuresTag)

  # make all directory logic explicit
  ImageRepresentations_df_transport <- ImageRepresentations_df <- myGlmnet_coefs <- loss_vec <- NULL
  orig_wd <- getwd()
  if( (cond1 <- substr(figuresPath, start = 0, stop = 1) == ".")  ){
    figuresPath <- gsub(figuresPath, pattern = '\\.', replacement = orig_wd)
  }
  if(!dir.exists(figuresPath)){ dir.create(figuresPath) }
  figuresPath <- paste(strsplit(figuresPath,split="/")[[1]],collapse = "/")
  if(batchSize > length(obsW)){ batchSize <- round(length(obsW) * 0.90) }

  XisNull <- is.null( X  )
  if(!XisNull){ if(!"matrix" %in% class(X)){
    message2("Coercing X to matrix class..."); X <- as.matrix(  X )
  } }

  if( !XisNull ){ if(is.na(sum(X))){ stop("Error: is.na(sum(X)) is TRUE; check for NAs or that all variables are numeric.") }}
  if( !XisNull ){ if(any(apply(X,2,sd) == 0)){ stop("Error: any(apply(X,2,sd) == 0) is TRUE; a column in X seems to have no variance; drop column!") }}
  if( XisNull ){ X <- matrix( rnorm(length(obsW)*2, sd = 0.01 ), ncol = 2) }
  X <- t( (t(X) - (X_mean <- colMeans(X)) ) / (0.001+(X_sd <- apply(X,2,sd))) )
  # clip extreme standardized values 
  X[X > 4] <- 4; X[X < -4] <- -4

  
  {
    message2("TfRecord management...")
    LocalFxnSource(TFRecordManagement, evaluation_environment = environment())

    if(useTrainingPertubations){
      trainingPertubations <- cienv$jax$vmap( 
        trainingPertubations_OneObs <- function(im_, key){
         # key <- cienv$jax$random$key(c(sample(1:100,1)))
         AB <- ifelse(dataType == "video", yes = 1L, no = 0L)
         which_path <- cienv$jnp$squeeze(cienv$jax$random$categorical(key = key, logits = cienv$jnp$array(t(rep(0, times = 4)))),0L)# generates random # from 0L to 3L
         
         # flip paths
         # which_path of 0L -> do no flips 
         im_ <- cienv$jax$lax$cond(cienv$jnp$equal(which_path,cienv$jnp$array(1L)),
                                   true_fun = function(){ cienv$jnp$flip(im_, 
                                                                         axis = AB+0L) }, 
                                   false_fun = function(){im_})
         im_ <- cienv$jax$lax$cond(cienv$jnp$equal(which_path,cienv$jnp$array(2L)), 
                                   true_fun = function(){ cienv$jnp$flip(im_, 
                                                                         axis = AB+1L) }, 
                                   false_fun = function(){im_})
         im_ <- cienv$jax$lax$cond(cienv$jnp$equal(which_path,cienv$jnp$array(3L)),
                                   true_fun = function(){ cienv$jnp$flip(cienv$jnp$flip(im_, 
                                                                                        axis = AB+0L),
                                                                         axis = AB+1L) }, 
                                   false_fun = function(){im_})
         
         # Add brightness perturbation (scalar addition)
         key <- cienv$jax$random$split(key)  # Use second key from split for next ops; discard first if not needed
         apply_bright <- cienv$jax$random$bernoulli(cienv$jax$random$split(key[[1]])[[1L]], p=0.25)
         im_ <- cienv$jax$lax$cond(apply_bright,
                                   true_fun = function(){ im_ + cienv$jax$random$uniform(cienv$jax$random$split(key[[1]])[[1]], minval=-0.1, maxval=0.1,dtype = im_$dtype)}, # delta noise 
                                   false_fun = function(){ im_ })
         
         # Add contrast perturbation (centered multiplication)
         key <- cienv$jax$random$split(key[[1]])
         apply_contrast <- cienv$jax$random$bernoulli(cienv$jax$random$split(key[[1]])[[1L]], p=0.25)
         im_ <- cienv$jax$lax$cond(apply_contrast,
                                   true_fun = function(){ im_ * cienv$jax$random$uniform(cienv$jax$random$split(key[[1]])[[1L]], minval=0.8, maxval=1.2,dtype=im_$dtype) },
                                   false_fun = function(){ im_ })
         
         # Add Gaussian noise perturbation (per-element)
         key <- cienv$jax$random$split(key[[1L]])
         apply_noise <- cienv$jax$random$bernoulli(cienv$jax$random$split(key[[1]])[[1L]], p=0.25)
         im_ <- cienv$jax$lax$cond(apply_noise,
                                   true_fun = function(){ im_ + cienv$jax$random$normal(cienv$jax$random$split(key[[1]])[[1L]], shape=cienv$jnp$shape(im_),dtype=im_$dtype) * 0.05},
                                   false_fun = function(){ im_ })
         return( im_ ) },
        in_axes = list(0L,0L))
    }

    InitImageProcessFn <- cienv$jax$jit(function(im, key, inference){
        # expand dims if needed
        if(length(imageKeysOfUnits) == 1){ im <- cienv$jnp$expand_dims(im,0L) }

        # normalize
        im <- (im - NORM_MEAN_array) / NORM_SD_array

        # downshift resolution if desired
        if(inputAvePoolingSize > 1 & dataType == "image"){
          im <- cienv$jax$vmap(function(imm){
            cienv$jnp$transpose(  cienv$eq$nn$AvgPool2d(kernel_size = ai(c(inputAvePoolingSize,inputAvePoolingSize)),
                            stride = ai(c(inputAvePoolingSize,inputAvePoolingSize)))(
                          cienv$jnp$transpose(imm,c(2L,0L,1L)  )), c(1L,2L, 0L)) }, 0L)(im)
        }
        
        # training pertubations
        if(useTrainingPertubations){
          im <- cienv$jax$lax$cond(inference, true_fun = function(){ im }, 
                                              false_fun = function(){  trainingPertubations(im, 
                                                              cienv$jax$random$split(key,im$shape[[1]])) } )
        }
        if(useScalePertubations){
          im <- cienv$jax$lax$cond(inference, true_fun = function(){ im }, 
                                              false_fun = function(){  scalePertubations(im, 
                                                                           cienv$jax$random$split(key,im$shape[[1]])) } )
        }
        return( im  )
    })

    message2("Calibrating first moments for input data normalization...")
    # Input to reshape is a tensor with 58800 values, but the requested shape has 19600
    NORM_MEAN_array <- GetMoments(ds_iterator_train, 
                                  dataType = dataType, 
                                  image_dtype = image_dtype, 
                                  momentCalIters = 34)
    NORM_SD <- NORM_MEAN_array$NORM_SD; NORM_SD_array <- NORM_MEAN_array$NORM_SD_array
    NORM_MEAN <- NORM_MEAN_array$NORM_MEAN; NORM_MEAN_array <- NORM_MEAN_array$NORM_MEAN_array
    EP_LSMOOTH <- cienv$jnp$array( 0.05 )
    cienv$py_gc$collect()

    # set up holders
    sigmoid <- function(x){1/(1+exp(-x))}
    prW_est <- rep(NA,times = length(obsW))
    tauHat_propensity_vec <- tauHat_propensityHajek_vec <- rep(NA,times = nBoot+1)
    if(!optimizeImageRep){
      message2("Note: Not optimizing image/video representation...")
      message2("Defining train/test indices based on out of sample keys...")
      imageKeysByTreatment <- tapply(obsW, imageKeysOfUnits, mean)
      outKeys <- try(c(sample(names(imageKeysByTreatment[imageKeysByTreatment > 0.5]), 
                          floor(max(c(2,length(unique(imageKeysOfUnits))*testFrac)) / 2)
                          ), 
                       sample(names(imageKeysByTreatment[imageKeysByTreatment <= 0.5]), 
                          floor(max(c(2,length(unique(imageKeysOfUnits))*testFrac)) / 2))
                       ), T)
      if("try-error" %in% class(outKeys)){ 
        outKeys <- sample(unique(imageKeysOfUnits), 
                          floor(max(c(2,length(unique(imageKeysOfUnits))*testFrac)))
                          ) 
      }
      inKeys <- unique(imageKeysOfUnits[!imageKeysOfUnits %in% outKeys])
      testIndices <- (1:length(obsY))[imageKeysOfUnits %in% outKeys]
      trainIndices <- (1:length(obsY))[imageKeysOfUnits %in% inKeys]

      message2("Starting generation of image/video representation + outcome prediction [bootstrap done for uncertainty estimation]...")
      for(jr in 1L:(nBoot+1L)){
        if(nBoot > 0L){ message2(sprintf("Bootstrap iteration %s of %s", jr-1L, nBoot) ) } 
        if(jr != (nBoot+1L)){ bindices_ <- sample(1:length( imageKeysOfUnits ), length( imageKeysOfUnits ), replace = T) }
        if(jr == (nBoot+1L)){ bindices_ <- 1:length( imageKeysOfUnits ) }

        # note: MyEmbeds_ are indexed by the original data ordering, resampling happens later
        {
          setwd(orig_wd); ImageRepresentations <- GetImageRepresentations(
            X = X,
            file = file,
            dataType = dataType,
            InitImageProcess = InitImageProcessFn,
            NORM_MEAN = NORM_MEAN, 
            NORM_SD = NORM_SD, 
            nWidth_ImageRep = nWidth_ImageRep,
            nDepth_ImageRep = nDepth_ImageRep,
            strides = strides,
            nonLinearScaler = nonLinearScaler,
            dropoutRate = 0,
            droppathRate = 0, 
            nDepth_TemporalRep = nDepth_TemporalRep,
            patchEmbedDim = patchEmbedDim,
            batchSize = batchSize,
            imageModelClass = imageModelClass,
            pretrainedModel = pretrainedModel, 
            optimizeImageRep = optimizeImageRep, 
            kernelSize = kernelSize,
            TfRecords_BufferScaler = 3L,
            XCrossModal = XCrossModal,
            XForceModal = XForceModal,
            inputAvePoolingSize = inputAvePoolingSize,
            lat = lat[!duplicated(imageKeysOfUnits)], 
            long = long[!duplicated(imageKeysOfUnits)], 
            imageKeysOfUnits = imageKeysOfUnits[!duplicated(imageKeysOfUnits)],
            getRepresentations = T,
            initializingFxns = F,
            returnContents = T,
            bn_momentum = 0.99,
            conda_env = conda_env,
            conda_env_required = conda_env_required,
            Sys.setenv_text = Sys.setenv_text,
            seed = ai(400L + jr)  ); setwd(new_wd)
          ImageRepresentations_df <- as.data.frame(  ImageRepresentations$ImageRepresentations )
          row.names(ImageRepresentations_df) <- as.character(unique(imageKeysOfUnits))
          ImageRepresentations_df <- ImageRepresentations_df[as.character(imageKeysOfUnits),]
       }
        # subset indices for training
        indices_forTraining <- bindices_[bindices_ %in% trainIndices]
        glmnetInput <- ifelse(XisNull, yes = list(ImageRepresentations_df),
                                       no = list(cbind(as.matrix(X), ImageRepresentations_df)))[[1]]
        if(any(is.na(glmnetInput))){ stop("Stopping due to NA in glmnetInput [Code ref: Confounding.R]") }
        myGlmnet_ <- glmnet::cv.glmnet(
          x = as.matrix(glmnetInput[indices_forTraining,]),
          y = as.matrix(obsW[indices_forTraining]),
          nfolds = 5,
          alpha = 0, # alpha = 0 is the ridge penalty
          type.measure = ifelse(length(unique(obsW))==2,yes="auc",no="default"),
          family = ifelse(length(unique(obsW))==2,yes="binomial",no="gaussian")
          )
        obsW_ <- obsW[bindices_]; obsY_ <- obsY[bindices_]
        prW_est_ <- predict(myGlmnet_, 
                            s = "lambda.min",
                            newx = as.matrix(glmnetInput[bindices_,]), 
                            type = "response")
        # plot(obsW_, c(prW_est_)); cor(obsW_, c(prW_est_)); tapply(prW_est_, obsW_, mean)
        # plot(obsW[indices_forTraining], c(predict(myGlmnet_, s ="lambda.min",newx = as.matrix(glmnetInput[indices_forTraining,]), type = "response")))

        # compute QOIs
        myGlmnet_coefs_ <- as.matrix( glmnet::coef.glmnet(myGlmnet_, s = "lambda.min") )
        tauHat_propensity_vec[jr] <- tauHat_propensity_ <- mean(  obsW_*obsY_/c(prW_est_) - 
                                                            (1-obsW_)*obsY_/c(1-prW_est_) )
        tauHat_propensityHajek_vec[jr] <- tauHat_propensityHajek_ <- sum(  obsY_*prop.table(obsW_/c(prW_est_))) -
                                            sum(obsY_*prop.table((1-obsW_)/c(1-prW_est_) ))
        if(jr == 1){ myGlmnet_coefs_mat <- matrix(NA, nrow = nBoot+1, ncol = length(myGlmnet_coefs_)) }
        myGlmnet_coefs_mat[jr,] <- c(myGlmnet_coefs_)
        if(jr == (nBoot+1L)){
          nTrainable <- length(  myGlmnet_coefs_  )
          tauHat_propensityHajek <- tauHat_propensityHajek_
          tauHat_propensity <- tauHat_propensity_
          myGlmnet_coefs <- myGlmnet_coefs_
          prW_est <- prW_est_
          GetTreatProb_batch <- function( ModelList, ModelList_fixed,
                                          m, x, seed,
                                          StateList, MPList, inference){
            ImageReps <- ImageRepArm_batch_R(ModelList_fixed, m, x,
                                             StateList, seed, MPList, inference)
            if(!XisNull){
                x_m <- cienv$jnp$concatenate(list( cienv$jnp$ones(list(m$shape[[1]],1L)), 
                                                   x, 
                                                   ImageReps[[1]] ), 1L)
            }
            if(XisNull){
              x_m <- cienv$jnp$concatenate(list( cienv$jnp$ones(list(m$shape[[1]],1L)), 
                                                 ImageReps[[1]] ), 1L)
            }
            my_probs <- cienv$jax$nn$sigmoid(  
                            cienv$jnp$matmul(x_m, ModelList$myGlmnet_coefs_tf ) 
                            )
            my_probs <- cienv$jnp$clip( my_probs, 1e-3, 1 - 1e-3)
            return( list(my_probs, StateList) )
          }
          ModelList <- list("myGlmnet_coefs_tf" = cienv$jnp$array(myGlmnet_coefs, dtype = cienv$jnp$float32))
          ModelList_fixed <- ImageRepresentations[["ImageModel_And_State_And_MPPolicy_List"]][[1]]
          StateList <- ImageRepresentations[["ImageModel_And_State_And_MPPolicy_List"]][[2]]
          MPList <- ImageRepresentations[["ImageModel_And_State_And_MPPolicy_List"]][[3]]
          ImageRepArm_batch_R <- ImageRepresentations$ImageRepArm_batch_R
          InitImageProcessFn <-  ImageRepresentations[["InitImageProcess"]]
          nParamsRep <- ImageRepresentations$nParamsRep
          
          if(!is.null(fileTransport)){
            setwd(orig_wd); ImageRepresentations_df_transport <- GetImageRepresentations(
              X = X,
              file = fileTransport,
              dataType = dataType,
              InitImageProcess = InitImageProcessFn,
              NORM_MEAN = NORM_MEAN, 
              NORM_SD = NORM_SD, 
              nWidth_ImageRep = nWidth_ImageRep,
              nDepth_ImageRep = nDepth_ImageRep,
              strides = strides,
              nonLinearScaler = nonLinearScaler,
              dropoutRate = 0,
              droppathRate = 0, 
              nDepth_TemporalRep = nDepth_TemporalRep,
              patchEmbedDim = patchEmbedDim,
              batchSize = batchSize,
              imageModelClass = imageModelClass,
              pretrainedModel = pretrainedModel, 
              optimizeImageRep = optimizeImageRep, 
              kernelSize = kernelSize,
              TfRecords_BufferScaler = 3L,
              XCrossModal = XCrossModal,
              XForceModal = XForceModal,
              inputAvePoolingSize = inputAvePoolingSize,
              lat = latTransport[!duplicated(imageKeysOfUnitsTransport)], 
              long = longTransport[!duplicated(imageKeysOfUnitsTransport)], 
              imageKeysOfUnits = imageKeysOfUnitsTransport[!duplicated(imageKeysOfUnitsTransport)], 
              getRepresentations = T,
              initializingFxns = F, 
              returnContents = T,
              bn_momentum = 0.99,
              conda_env = conda_env,
              conda_env_required = conda_env_required,
              Sys.setenv_text = Sys.setenv_text,
              seed = ai(400L + jr)  ); setwd(new_wd)
            ImageRepresentations_df_transport <- as.data.frame(  ImageRepresentations_df_transport$ImageRepresentations )
          }
        }
      }
    }

    if(optimizeImageRep){
      justCheckIterators <- FALSE
      if( ! crossFit ){ kFolds <- 1L }
      if( crossFit ){ 
        kFolds <- 3L 
        nUniqueKeys <- length( unique( imageKeysOfUnits ) )
        cf_keys_split <- 1*as.numeric(cut(1:nUniqueKeys,kFolds))
        cf_keys_split <- sapply( 1:kFolds, function(l_){ list(which(cf_keys_split==l_))})
        cf_keys_toSkip_bounds <- lapply(cf_keys_split,function(l_){c(min(l_), max(l_))})
        
        # shuffle for outer CF iteration 
        if( is.null(TFRecordControl)){
          tf_dataset_master <- cienv$tf$data$TFRecordDataset(  tf_record_name[length(tf_record_name)] )
          tf_dataset_master_ <- getParsed_tf_dataset_train_Shuffle( tf_dataset_master )
        }
        
        # Define master datasets and fold splits outside the loop (after tf_dataset_master_ definition in if(crossFit))
        if( !is.null(TFRecordControl) ){
          tf_dataset_master_control <- cienv$tf$data$TFRecordDataset(tf_record_name[length(tf_record_name)])$skip(
                                                        ai(TFRecordControl$nTest) )$take(
                                                                ai(TFRecordControl$nControl))
          tf_dataset_master_control_ <- getParsed_tf_dataset_train_Shuffle(tf_dataset_master_control)
          
          tf_dataset_master_treated <- cienv$tf$data$TFRecordDataset(tf_record_name[length(tf_record_name)])$skip(
                                                  ai(TFRecordControl$nTest + TFRecordControl$nControl+1L))$take(
                                                          ai(TFRecordControl$nTreatment))
          tf_dataset_master_treated_ <- getParsed_tf_dataset_train_Shuffle(tf_dataset_master_treated)
          
          nUniqueKeys_control <- TFRecordControl$nControl
          cf_keys_split_control <- 1 * as.numeric(cut(1:nUniqueKeys_control, kFolds))
          cf_keys_split_control <- sapply(1:kFolds, function(l_) { list(which(cf_keys_split_control == l_)) })
          cf_keys_toSkip_bounds_control <- lapply(cf_keys_split_control, function(l_) { c(min(l_), max(l_)) })
          nUniqueKeys_treated <- TFRecordControl$nTreatment
          cf_keys_split_treated <- 1 * as.numeric(cut(1:nUniqueKeys_treated, kFolds))
          cf_keys_split_treated <- sapply(1:kFolds, function(l_) { list(which(cf_keys_split_treated == l_)) })
          cf_keys_toSkip_bounds_treated <- lapply(cf_keys_split_treated, function(l_) { c(min(l_), max(l_)) })
        }
      }
      tauHat_propensityHajek_vec <- rep(NA,times=kFolds)
      trainIndices_list <- testIndices_list <- list() 
      for( kf_ in 1:kFolds ){
      message2(sprintf("k fold %s of %s",kf_,kFolds))
      
      # set up cross fitted iterators 
      if( crossFit ){ 
        if( is.null(TFRecordControl)){
          # select a tf record indexed to (1:kFolds([!1:kFolds %in% kf_] (skip indices bounded by cf_keys_toSkip_bounds)
          if(kf_ == 1){ 
            tf_dataset_train <- getParsed_tf_dataset_train_Select(
              tf_dataset_master_$skip( ai(cf_keys_toSkip_bounds[[kf_]][2]) ) )$`repeat`(-1L) 
          }
          if(kf_ == kFolds){ 
            tf_dataset_train <- getParsed_tf_dataset_train_Select(
              tf_dataset_master_$take( ai(cf_keys_toSkip_bounds[[kf_]][1]-1L) ) )$`repeat`(-1L) 
          }
          if(kf_ > 1 & kf_ < kFolds){ 
            tf_dataset_train <- getParsed_tf_dataset_train_Select(
              tf_dataset_master_$take( ai(cf_keys_toSkip_bounds[[kf_]][1]-1L) )$concatenate(
                tf_dataset_master_$skip( ai(cf_keys_toSkip_bounds[[kf_]][2]) ) ))$`repeat`(-1L) # repeat to avoid out of sequence errors 
          }
          tf_dataset_train <- getParsed_tf_dataset_train_BatchAndShuffle( tf_dataset_train )
          ds_iterator_train <- reticulate::as_iterator( tf_dataset_train )
        }
        if( !is.null(TFRecordControl)){
          # control 
          if(kf_ == 1){
            tf_dataset_train_control <- getParsed_tf_dataset_train_Select(
              tf_dataset_master_control_$skip(ai(cf_keys_toSkip_bounds_control[[kf_]][2]))
            )$`repeat`(-1L)
          }
          if(kf_ > 1 & kf_ < kFolds){
            tf_dataset_train_control <- getParsed_tf_dataset_train_Select(
              tf_dataset_master_control_$take(ai(cf_keys_toSkip_bounds_control[[kf_]][1] - 1L))$concatenate(
                tf_dataset_master_control_$skip(ai(cf_keys_toSkip_bounds_control[[kf_]][2]))
              )
            )$`repeat`(-1L)
          }
          if(kf_ == kFolds){
            tf_dataset_train_control <- getParsed_tf_dataset_train_Select(
              tf_dataset_master_control_$take(ai(cf_keys_toSkip_bounds_control[[kf_]][1] - 1L))
            )$`repeat`(-1L)
          }
          
          # treat
          if(kf_ == 1){
            tf_dataset_train_treated <- getParsed_tf_dataset_train_Select(
              tf_dataset_master_treated_$skip(ai(cf_keys_toSkip_bounds_treated[[kf_]][2]))
            )$`repeat`(-1L)
          }
          if(kf_ > 1 & kf_ < kFolds){
            tf_dataset_train_treated <- getParsed_tf_dataset_train_Select(
              tf_dataset_master_treated_$take(ai(cf_keys_toSkip_bounds_treated[[kf_]][1] - 1L))$concatenate(
                tf_dataset_master_treated_$skip(ai(cf_keys_toSkip_bounds_treated[[kf_]][2]))
              )
            )$`repeat`(-1L)
          }
          if(kf_ == kFolds){
            tf_dataset_train_treated <- getParsed_tf_dataset_train_Select(
              tf_dataset_master_treated_$take(ai(cf_keys_toSkip_bounds_treated[[kf_]][1] - 1L))
            )$`repeat`(-1L)
          }
          tf_dataset_train_control <- getParsed_tf_dataset_train_BatchAndShuffle( tf_dataset_train_control )
          tf_dataset_train_treated <- getParsed_tf_dataset_train_BatchAndShuffle( tf_dataset_train_treated )
          ds_iterator_train_control <- reticulate::as_iterator( tf_dataset_train_control )
          ds_iterator_train_treated <- reticulate::as_iterator( tf_dataset_train_treated )
        }
      }
        
      seed <- seed + as.integer(kf_)
      setwd(orig_wd); ImageRepresentations <- GetImageRepresentations(
        X = X,
        file = file,
        dataType = dataType,
        InitImageProcess = InitImageProcessFn,
        NORM_MEAN = NORM_MEAN, 
        NORM_SD = NORM_SD, 
        nWidth_ImageRep = nWidth_ImageRep,
        nDepth_ImageRep = nDepth_ImageRep,
        strides = strides,
        nonLinearScaler = nonLinearScaler,
        dropoutRate = dropoutRate,
        droppathRate = droppathRate, 
        nDepth_TemporalRep = nDepth_TemporalRep,
        patchEmbedDim = patchEmbedDim,
        batchSize = batchSize,
        imageModelClass = imageModelClass,
        pretrainedModel = pretrainedModel, 
        optimizeImageRep = optimizeImageRep, 
        kernelSize = kernelSize,
        inputAvePoolingSize = inputAvePoolingSize,
        TfRecords_BufferScaler = 3L,
        XCrossModal = XCrossModal,
        XForceModal = XForceModal,
        imageKeysOfUnits = (UsedKeys <- sample(unique(imageKeysOfUnits),min(c(length(unique(imageKeysOfUnits)),2*batchSize)))), getRepresentations = T,
        returnContents = T,
        initializingFxns = T, 
        bn_momentum = 0.99,
        conda_env = conda_env,
        conda_env_required = conda_env_required,
        Sys.setenv_text = Sys.setenv_text,
        seed = ai(4003L + seed)  ); setwd(new_wd)
        ImageModel_And_State_And_MPPolicy_List <- ImageRepresentations[["ImageModel_And_State_And_MPPolicy_List"]]
        ImageRepArm_batch_R <- ImageRepresentations[["ImageRepArm_batch_R"]]
        InitImageProcessFn <-  ImageRepresentations[["InitImageProcess"]]
        rm( ImageRepresentations )

        batch_axis_name <- "batch"
        DenseList <- DenseStateList <- replicate(nDepth_Dense, list())
        for(d_ in 1L:nDepth_Dense){
          DenseProj_d <- cienv$eq$nn$Linear(in_features = ind_ <- ifelse(d_ == 1, 
                                                          yes = (nWidth_ImageRep + ifelse(XisNull, no = ncol(X)*(!XCrossModal), yes = 0L)),
                                                          no =  nWidth_Dense),
                                      out_features = outd_ <- ifelse(d_ == nDepth_Dense,
                                                      yes = 1L,  no = nWidth_Dense),
                                      use_bias = T, key = cienv$jax$random$key(d_ + 44L + as.integer(seed)))
          #LayerBN_d  <- cienv$eq$nn$BatchNorm( input_size = outd_, axis_name = batch_axis_name, momentum = 0.99, eps = 0.001, channelwise_affine = F)
          LayerBN_d <- cienv$jnp$array(1)
          DenseStateList[[d_]] <- list('BNState' = cienv$eq$nn$State( LayerBN_d ))
          DenseList[[d_]] <- list("DenseProj" = DenseProj_d,
                                  "BN" = LayerBN_d)
        }
        names(DenseList) <- names(DenseStateList) <- paste0("Dense", 1:nDepth_Dense)

        # ModelList <- DenseList; StateList <- DenseStateList
        GetDense_OneObs <- function(ModelList, ModelList_fixed, m, x,
                                    seed, StateList, MPList, inference){
          message2("Starting GetDense_OneObs()")
          
          if(!XCrossModal){
            if(!XisNull){  m <- cienv$jnp$concatenate(list(m,x))  }
          }

          for(d__ in 1:nDepth_Dense){
            eval(parse(text = sprintf("DenseList_d <- ModelList$DenseList$Dense%s",d__)))
            eval(parse(text = sprintf("StateDenseList_d <- StateList$DenseStateList$Dense%s",d__)))
            
            # View(cienv$np$array(m$val))
            m <- DenseList_d$DenseProj(  m  )

            # BN + non-linearity
            if(d__ < nDepth_Dense){
              m <- DenseList_d$BN(m, state = StateDenseList_d, inference = inference)
              eval(parse(text = sprintf("StateList$DenseList$Dense%s <- m[[2]]", d__)))
              m <- m[[1]]

              # Non-linearity
              m <- cienv$jax$nn$swish(  m   )
            }
          }
          
          message2("Returning output and state in GetDense_OneObs()...")
          return( list(m, StateList)  )
        }
        GetDense_batch <- cienv$jax$vmap(  function(
                  ModelList, ModelList_fixed,
                  m, x, seed,
                  StateList, MPList, inference){
                    GetDense_OneObs(ModelList, ModelList_fixed, m, x, seed, StateList, MPList, inference)
                },
                in_axes = list(NULL, NULL, 0L, 0L, 0L, NULL, NULL, NULL),
                   axis_name = batch_axis_name,
                   out_axes = list(0L, NULL) )
        GetDense_batch_jit <- cienv$eq$filter_jit(   GetDense_batch  )
        GetTreatProb_batch <- function( ModelList, ModelList_fixed,
                                        m, x, seed,
                                        StateList, MPList, inference){
          message2("In GetTreatProb_batch() - image model")
          m <- ImageRepArm_batch_R(ModelList, m, x,
                                   StateList, seed, MPList, inference)
          StateList <- m[[2]]; m <- m[[1]]

          message2("In GetTreatProb_batch() - dense model")
          m <- GetDense_batch(ModelList, ModelList_fixed, m, x, seed, StateList, MPList, inference)
          StateList <- m[[2]]; m <- m[[1]]
          
          # sigmoid 
          m <- cienv$jnp$clip( cienv$jax$nn$sigmoid( m ), 1e-3, 1 - 1e-3)
          
          # return contents
          return( list(m, StateList) )
        }

        GetLoss <-  function( ModelList, ModelList_fixed,
                              m, x, treat, y, seed,
                              StateList, MPList, inference ){
          ModelList <- MPList[[1]]$cast_to_compute( ModelList ) # compute to output dtype
          ModelList_fixed <- MPList[[1]]$cast_to_compute( ModelList_fixed ) # compute to output dtype
          StateList <- MPList[[1]]$cast_to_compute( StateList ) # compute to output dtype

          m <- GetTreatProb_batch( ModelList, ModelList_fixed,
                                   m, x, seed,
                                   StateList, MPList, inference )
          StateList <- m[[2]]; m <-  m[[1]]

          # compute negative log-likelihood loss
          m <- MPList[[1]]$cast_to_output( m )
          # NegLL <-  cienv$jnp$mean( cienv$jnp$negative(  treat*cienv$jnp$log(m) + (1-treat)*cienv$jnp$log(1-m) )  ) 
          # compute smoothed negative log-likelihood
          treat_smooth <- (1 - EP_LSMOOTH) * treat + EP_LSMOOTH / 2.
          NegLL <- cienv$jnp$mean(
            cienv$jnp$negative(
              treat_smooth * cienv$jnp$log(m) + 
                (1 - treat_smooth) * cienv$jnp$log(1 - m)
            )
          )

          message2("Returning loss + state...")
          if(image_dtype_char == "float16"){ 
            NegLL <- MPList[[1]]$cast_to_output( NegLL ) # compute to output dtype
            NegLL <- MPList[[2]]$scale( NegLL ) # scale loss
            StateList <- MPList[[1]]$cast_to_param( StateList ) # compute to param dtype
          }

          # return
          return( list(NegLL, StateList)  )
        }

        gc(); cienv$py_gc$collect()
        message2("Set state and model lists..." ) 
        GradAndLossAndAux <-  cienv$eq$filter_jit( cienv$eq$filter_value_and_grad( GetLoss, has_aux = T) )
        ModelList <- c(ImageModel_And_State_And_MPPolicy_List[[1]], "DenseList" = list(DenseList))
        StateList <- c(ImageModel_And_State_And_MPPolicy_List[[2]], "DenseStateList" = list(DenseStateList))
        ModelList_fixed <- cienv$jnp$array(0.)
        MPList <- list(cienv$jmp$Policy(compute_dtype=ComputeDtype, 
                                  param_dtype="float32", 
                                  output_dtype=(outputDtype <- ComputeDtype)),
                       cienv$jmp$DynamicLossScale(loss_scale = cienv$jnp$array(2^15,dtype = ComputeDtype ),
                                            min_loss_scale = cienv$jnp$array(2^1.,dtype = ComputeDtype ),
                                            period = 50L))
        ModelList <- MPList[[1]]$cast_to_param( ModelList )
        ModelList_fixed <- MPList[[1]]$cast_to_param( ModelList_fixed )
        rm( ImageModel_And_State_And_MPPolicy_List, DenseStateList, DenseList )
        
        message2("Define trainer...")
        LocalFxnSource(TrainDefine, evaluation_environment = environment())
        
        message2("Starting training...")
        LocalFxnSource(TrainDo, evaluation_environment = environment())
        
        # check iterators 
        {
          # usedKeys  == unique(imageKeysOfUnits)
          # unlist(Results_by_keys[["key"]]) == unique(imageKeysOfUnits)
          # mean(unlist(Results_by_keys[["key"]]) %in% imageKeysOfUnits)
          # mean(imageKeysOfUnits %in% unlist(  Results_by_keys[["key"]] ))
          trainIndices <- which( imageKeysOfUnits %in% keysUsedInTraining )
          testIndices <- which( !imageKeysOfUnits %in% keysUsedInTraining )
          trainIndices_list[kf_] <- list(trainIndices)
          testIndices_list[kf_] <- list(testIndices)
          if(FALSE){ 
            # sanity checks 
            # note: there will be some overlap in test due to TRUE test indices 
            length(unique(unlist(trainIndices_list)))
            length(unique(unlist(testIndices_list)))
            plot(testIndices_list[[2]] %in% testIndices_list[[1]])
            plot(testIndices_list[[1]] %in% testIndices_list[[2]])
            plot(testIndices_list[[1]] %in% testIndices_list[[3]])
            
            table(obsW[ testIndices_list[[1]] %in% testIndices_list[[2]] ])
            table(obsW[ !testIndices_list[[1]] %in% testIndices_list[[2]] ])
            
            table(obsW[ testIndices_list[[1]] %in% testIndices_list[[3]] ])
            table(obsW[ !testIndices_list[[1]] %in% testIndices_list[[3]] ])
            
            mean(testIndices_list[[1]] %in% testIndices_list[[2]])
            mean(testIndices_list[[2]] %in% testIndices_list[[3]])
            mean(testIndices_list[[1]] %in% testIndices_list[[3]])
            mean(trainIndices_list[[1]] %in% trainIndices_list[[3]])
          }
        }
        
        # inference on all observations
        if(!justCheckIterators){
          message2("Getting predicted quantities...")
          #GetImageArm_OneX <- cienv$eq$filter_jit( function(ModelList, ModelList_fixed,
          #                                                  m, x, seed,
          #                                                  StateList, MPList){
            # image representation model
          #  m <- ImageRepArm_batch_R(ModelList, m, x, 
          #                           StateList, seed, MPList, T)
          #  StateList <- m[[2]] ; m <- m[[1]]
            
          # sigmoid 
          #  m <- cienv$jnp$clip( cienv$jax$nn$sigmoid( m ), 1e-3, 1 - 1e-3)
            
          #  return( m )
          #})
          
          # Get predicted quantities 
          {    
            t0_inference <- Sys.time();gc()
            inf_counter <- 0
            nUniqueKeys <- length( unique(imageKeysOfUnits) )
            KeyQuantCuts <- 1L:nUniqueKeys
            batchSize <- ai(2L*batchSize) # double the batch size for inference 
            batchStarts <- seq(1L, nUniqueKeys, by = batchSize)
            passedIterator <- NULL; Results_by_keys <- list()
            ImageRepArm_batch_jit <- cienv$eq$filter_jit( ImageRepArm_batch_R )
            pb <- txtProgressBar(min = 0, max = length(batchStarts), style = 3)  # Initialize progress bar
            usedKeys <- c(); for (b in seq_along(batchStarts)) {
              idx_start <- batchStarts[b]
              # 2.390  mins to 10k, 2*batchSize
              if( idx_start>1000  & !"tk1000" %in% ls()){ tk1000 <- TRUE;message2(sprintf("Time to >1000 inference fits: [%.3f mins]",difftime(Sys.time(),t0_inference,units="min") )) }
              if( idx_start>10000  & !"tk10000" %in% ls()){ tk10000 <- TRUE;message2(sprintf("Time to >10000 inference fits: [%.3f mins]",difftime(Sys.time(),t0_inference,units="min") )) }
              idx_end   <- min(idx_start + batchSize - 1L, nUniqueKeys)
              m_indices1 <- idx_start:idx_end  
              
              #gc(); cienv$py_gc$collect()
              if( any(m_indices1 %% 10 == 0) | 1 %in% m_indices1 ){ setTxtProgressBar(pb, b) }
              setwd(orig_wd); ds_next_in <- try(GetElementFromTfRecordAtIndices(
                uniqueKeyIndices = which(unique(imageKeysOfUnits) %in% unique(imageKeysOfUnits)[m_indices1]),
                filename = file,
                iterator = passedIterator,
                readVideo = useVideoIndicator,
                image_dtype = image_dtype_tf,
                nObs = length(unique(imageKeysOfUnits)),
                return_iterator = TRUE ),T); setwd(new_wd)
              tmp_updated_iterator <- ds_next_in[[2]]
              outerBatchKeys <- unlist(  lapply( p2l(ds_next_in[[1]][[3]]$numpy() ), as.character) )
              ds_next_in <-  cienv$jnp$array( ds_next_in[[1]][[1]] )
              if( !all(outerBatchKeys==unique(imageKeysOfUnits)[m_indices1]) ){
                stop("Key pairing mismatch in inference mode; check data! [Code ref. 134z]")
              }
              
              # get summaries and save
              usedKeys <- c(usedKeys, outerBatchKeys)
              keyNames_xIndicesValues <- do.call(rbind, 
                                                 sapply(outerBatchKeys, function(key__){ 
                                                   val__ <- which(imageKeysOfUnits %in% key__)
                                                   list(cbind("key"=rep(key__,times=length(val__)),"value"=val__))
                                                 }))
              keyNames_xIndicesValues_names <- keyNames_xIndicesValues[,1]
              keyNames_xIndicesValues <- f2n(keyNames_xIndicesValues[,2])
              names(keyNames_xIndicesValues) <- keyNames_xIndicesValues_names
              # mean(names(keyNames_xIndicesValues) == names(keyNames_xIndicesValues))
              
              # inner loop 
              batchStarts_inner <- seq(1, length(keyNames_xIndicesValues), by = batchSize)
              for(bi_ in seq_along(batchStarts_inner)){
                inf_counter <- inf_counter + 1
                idx_start_inner <- batchStarts_inner[bi_]
                idx_end_inner   <- idx_start_inner + batchSize - 1L
                
                in_xbatch_indices <- idx_start_inner:idx_end_inner
                x_indices <- keyNames_xIndicesValues[in_xbatch_indices]
                in_xbatch_indices <- in_xbatch_indices[!is.na(x_indices)]
                x_indices <- x_indices[!is.na(x_indices)]
                
                # get real size 
                realSize_inner  <- length(in_xbatch_indices)
                
                # Pad last batch to 'batchSize' by repeating the final key index
                in_xbatch_indices <- c(in_xbatch_indices,
                                       rep(in_xbatch_indices[realSize_inner],
                                           batchSize - realSize_inner))
                m_indices <- match(names(x_indices), outerBatchKeys)
                
                # get image rep 
                if(all(m_indices %in% 1:length(m_indices))){ 
                  m <- InitImageProcessFn(cienv$jnp$array(ds_next_in), cienv$jax$random$key(ai(600L+inf_counter)), 
                                          inference = TRUE)
                }
                if(!all(m_indices %in% 1:length(m_indices))){ 
                  m <- InitImageProcessFn(cienv$jnp$take(cienv$jnp$array(ds_next_in),
                                                         cienv$jnp$array(ai(m_indices-1L)), axis = 0L), cienv$jax$random$key(ai(600L+inf_counter)), 
                                          inference = TRUE)
                }
                x <- cienv$jnp$array(X[x_indices[in_xbatch_indices],], dtype = cienv$jnp$float16)
                if(batchSize != realSize_inner){
                  m <- cienv$jnp$take(m,
                                      cienv$jnp$array(in_xbatch_indices - 1L),
                                      axis=0L)
                }
                if(batchSize != m$shape[[1]]){stop("batchSize != m$shape[[1]] don't align in CI_Confounding.R")}
                m <- ImageRepArm_batch_jit(ifelse(optimizeImageRep, 
                                                  yes = list(ModelList), 
                                                  no = list(ModelList_fixed) )[[1]],
                                           m, 
                                           x, 
                                           StateList,
                                           cienv$jax$random$split(cienv$jax$random$key(ai(900L+inf_counter)),batchSize), #
                                           MPList, TRUE)[[1]]
                
                # get final output from image rep 
                # if(b==1){ m_b <- m; x_b <- x }
                # plot(cienv$np$array(x)[2,],X[2,]);abline(a=0,b=1)
                m <- GetDense_batch_jit(ModelList, ModelList_fixed,
                                        m,
                                        x, 
                                        cienv$jax$random$split(cienv$jax$random$key(as.integer(runif(1,0, 10000))), 
                                                               batchSize),
                                        StateList,
                                        MPList, TRUE)[[1]]
                m <- cienv$jnp$clip( cienv$jax$nn$sigmoid( m ), 1e-3, 1 - 1e-3)
                m <- as.matrix(cienv$np$array(m))
                
                ret_list <- list("ProbW" = m[1:realSize_inner,],
                                 "obsIndex" = as.matrix(x_indices[1:realSize_inner]),
                                 "key" = as.matrix( names(x_indices[1:realSize_inner]) ))
                Results_by_keys <- append(Results_by_keys, list(ret_list))
              }
              passedIterator <- tmp_updated_iterator # update iterator 
            }; close(pb) 
            Results_by_keys_orig <- Results_by_keys
            Results_by_keys <- do.call(rbind.data.frame, Results_by_keys)
            Results_by_keys <- Results_by_keys[order(f2n(Results_by_keys$obsIndex)),]
            Results_by_keys1 <- Results_by_keys
            message2(sprintf("Inference time: %.3f min", difftime(Sys.time(), t0_inference,units="min")))
          }
          
          # plot(f2n(Results_by_keys$ProbW),f2n(Results_by_keys1$ProbW));abline(a=0,b=1)
          # plot(f2n(Results_by_keys$ProbW)[1:10],f2n(Results_by_keys1$ProbW)[1:10]);abline(a=0,b=1)
          # plot(f2n(Results_by_keys$ProbW)[1:10]-f2n(Results_by_keys1$ProbW)[1:10]);abline(h=0)
          
          if( !all(Results_by_keys1$key == imageKeysOfUnits) ){
            stop("Problem in key alignment [code ref 3zf3]")
          }
          
          prW_est <-  Results_by_keys$ProbW <-  f2n(  Results_by_keys$ProbW ) 
          if(any(is.na(prW_est))){
            warning("NAs in output probabilities...Imputing them with average estimate")
            prW_est[is.na(prW_est)] <- mean(prW_est, na.rm = T)
          }
          
          # save QOI 
          if(!crossFit){ 
            tauHat_propensityHajek <- sum(  obsY*prop.table(obsW/c(prW_est))) - 
                       sum(obsY*prop.table((1-obsW)/c(1-prW_est) )) 
            tauHat_propensityHajek_vec <- unlist(replicate(nBoot, { 
                      i_ <- sample(1:length(obsW),length(obsW), T)
                          sum(  obsY[i_]*prop.table(obsW[i_]/c(prW_est[i_]))) -
                            sum(obsY[i_]*prop.table((1-obsW[i_]) / (1-prW_est[i_]) )) } ))
            tauHat_propensityHajek <- mean(tauHat_propensityHajek_vec,na.rm=T)
            tauHat_propensityHajek_se <- sd(tauHat_propensityHajek_vec,na.rm=T) 
          }
          if(crossFit){ 
            tauHat_propensityHajek_vec[kf_] <- sum(  obsY[testIndices]*prop.table(obsW[testIndices]/c(prW_est[testIndices]))) - 
                sum(obsY[testIndices]*prop.table((1-obsW[testIndices])/c(1-prW_est[testIndices]) )) 
          }
        }
      }
      
      if(crossFit){
        tauHat_propensityHajek <- mean(tauHat_propensityHajek_vec)
        tauHat_propensityHajek_se <- sd(tauHat_propensityHajek_vec) / 
                                      sqrt(length(tauHat_propensityHajek_vec))  
      }
      
      # define true test indices 
      trainIndices <- sort(unlist(trainIndices_list))
      testIndices <- (1:length(obsY))[! ((1:length(obsY)) %in%  trainIndices)] 
    }
    
    
    if(!is.null(TFRecordControl) & TRUE){
      testIndices_byClass <- tapply(testIndices, obsW[testIndices],c)
      minPerClass <- min(unlist(lapply(testIndices_byClass,length)))
      testIndices <- c(sample(testIndices_byClass[[1]],minPerClass),
                       sample(testIndices_byClass[[2]],minPerClass))
      table(obsW[testIndices])
    }

    # process in and out of sample losses
    prWEst_baseline <- prW_est 
    prWEst_baseline[] <- mean( obsW[trainIndices] )
    
    # model evaluation metrics 
    { 
    # cross entropy loss calcs
    binaryCrossLoss <- function(W,prW){ return( - mean( log(prW)*W + log(1-prW)*(1-W) ) ) }
    lossCE_OUT_baseline <- binaryCrossLoss(obsW[testIndices], prWEst_baseline[testIndices])
    lossCE_IN_baseline <- binaryCrossLoss(obsW[trainIndices], prWEst_baseline[trainIndices])
    lossCE_OUT <-  binaryCrossLoss(  obsW[testIndices], prW_est[testIndices]  )
    lossCE_IN <-  binaryCrossLoss(  obsW[trainIndices], prW_est[trainIndices]  )

    # class error calcs
    lossClassError_OUT_baseline <- 1/length(testIndices) * (sum( prWEst_baseline[testIndices][ obsW[testIndices] == 1] < 0.5) +
                           sum( prWEst_baseline[testIndices][ obsW[testIndices] == 0] > 0.5))
    lossClassError_IN_baseline <- 1/length(trainIndices) * (sum( prWEst_baseline[trainIndices][ obsW[trainIndices] == 1] < 0.5) +
                                                              sum( prWEst_baseline[trainIndices][ obsW[trainIndices] == 0] > 0.5))
    lossClassError_OUT <- 1/length(testIndices) * (sum( prW_est[testIndices][ obsW[testIndices] == 1] < 0.5) +
                           sum( prW_est[testIndices][ obsW[testIndices] == 0] > 0.5))
    lossClassError_IN <- 1/length(trainIndices) * (sum( prW_est[trainIndices][ obsW[trainIndices] == 1] < 0.5) +
                                                     sum( prW_est[trainIndices][ obsW[trainIndices] == 0] > 0.5))
    
    # AOC calculations
    roc_obj_IN <- pROC::auc(pROC::roc(response = obsW[trainIndices], 
                                      predictor = prW_est[trainIndices],
                                      levels = c(0, 1), direction = "<"))  # Assuming 1 is positive class
    roc_obj_OUT <- pROC::auc(pROC::roc(response = obsW[testIndices], 
                                       predictor = prW_est[testIndices], 
                                       levels = c(0, 1),
                                       direction = "<") ) # Assuming 1 is positive class
    
    # AUPRC calculations 
    auprc_OUT <- PRROC::pr.curve(scores.class0 = prW_est[testIndices][obsW[testIndices] == 1],
                                 scores.class1 = prW_est[testIndices][obsW[testIndices] == 0], 
                                 curve = FALSE)$auc.integral
    auprc_IN  <- PRROC::pr.curve(scores.class0 = prW_est[trainIndices][obsW[trainIndices] == 1],
                                 scores.class1 = prW_est[trainIndices][obsW[trainIndices] == 0],
                                 curve = FALSE)$auc.integral
    
    # store output
    ModelEvaluationMetrics <- list(
      "AUC_out" = roc_obj_OUT, 
      "AUC_in" = roc_obj_IN, 
      "AUPRC_out" = auprc_OUT,
      "AUPRC_in" = auprc_IN,
      "CELoss_out" = lossCE_OUT,
      "CELoss_out_baseline" = lossCE_OUT_baseline,
      "CELoss_in" = lossCE_IN,
      "CELoss_in_baseline" = lossCE_IN_baseline,
      "ClassError_out" = lossClassError_OUT,
      "ClassError_out_baseline" = lossClassError_OUT_baseline,
      "ClassError_in" = lossClassError_IN,
      "ClassError_in_baseline" = lossClassError_IN_baseline
    )
    }
    
    # reset to original wd which was altered during records initialization
    # do this before plotting to avoid disrupting plot save locations
    if( changed_wd ){ setwd(  orig_wd  ) }

    # do some analysis with examples
    processedDims <- NULL; {
      message2("Plotting image confounding results...")
      indices_t <- (1:length(obsW))[which(obsW==1)]
      indices_c <- (1:length(obsW))[which(obsW==0)]

      showPerGroup <- min(c(3,unlist(table(obsW))), na.rm = T)
      top_control <- ordered_control <- indices_c[order_c <- order(prW_est[indices_c],decreasing = F)]
      top_treated <- ordered_treated <- indices_t[order_t <- order(prW_est[indices_t],decreasing = T)]

      # drop duplicates
      if(!is.null(long)){
        longLat_t <- paste(round(long[indices_t[order_t]],5L),
                                round(lat[indices_t[order_t]],5L),sep="_")
        longLat_c <- paste(round(long[indices_c[order_c]],5L),
                                round(lat[indices_c[order_c]],5L),sep="_")
        top_treated <- ordered_treated[!duplicated(longLat_t)]
        top_control <- ordered_control[!duplicated(longLat_c)]
      }
      plot_indices <- c( top_control <- top_control[1:showPerGroup],
                         top_treated <- top_treated[1:showPerGroup] )

      for(pos_ in 2L:3L){
        dLogProb_d <- cienv$jax$grad(function(ModelList, ModelList_fixed,
                                        m, x, seed,
                                        StateList,  MPList, inference){
                    ModelList <- MPList[[1]]$cast_to_param( ModelList )
                    ModelList_fixed <- MPList[[1]]$cast_to_param( ModelList_fixed )
                    StateList <- MPList[[1]]$cast_to_param( StateList )
                    m <- MPList[[1]]$cast_to_param( m ); x <- MPList[[1]]$cast_to_param( x )
                    m <- cienv$jax$device_put(m, cienv$jax$devices('cpu')[[1]])
                    out_ <-  GetTreatProb_batch(ModelList, ModelList_fixed,
                                           m, x, seed,
                                           StateList, MPList, T)[[1]]  # scaling for non-zero gradients
                    out_ <- cienv$jnp$log(out_ / (1-out_))
                    return(  cienv$jnp$squeeze(out_)  ) }, pos_)
        if(pos_ == 2L){ dLogProb_dImage <- dLogProb_d }
        if(pos_ == 3L){ dLogProb_dX <- cienv$eq$filter_jit( dLogProb_d ) }
      }
      ImGrad_fxn <- cienv$eq$filter_jit( function(ModelList, ModelList_fixed,
                                            m, x, seed,
                                            StateList, MPList){
        # cast to float32
        ModelList <- MPList[[1]]$cast_to_param( ModelList )
        ModelList_fixed <- MPList[[1]]$cast_to_param( ModelList_fixed )
        StateList <- MPList[[1]]$cast_to_param( StateList )
        m <- MPList[[1]]$cast_to_param( m ); x <- MPList[[1]]$cast_to_param( x )
        m <- cienv$jax$device_put(m, cienv$jax$devices('cpu')[[1]])
        ImageGrad_o <- cienv$jnp$squeeze(dLogProb_dImage(ModelList, ModelList_fixed,
                                       m, x, seed, StateList, MPList), 0L)
        reduceDim <- ifelse( dataType == "video", yes = 3L, no = 2L)
        ImageGrad_L2 <- cienv$jnp$linalg$norm(ImageGrad_o+0.000001, axis = reduceDim, keepdims = T)
        ImageGrad_mean <- cienv$jnp$mean(ImageGrad_o, axis = reduceDim, keepdims = T)
        return( list(ImageGrad_L2,  # salience magnitude
                     ImageGrad_mean) ) # salience direction
      }, device = cienv$jax$devices('cpu')[[1]])
      MPList <- list(cienv$jmp$Policy(compute_dtype="float32", param_dtype="float32", output_dtype="float32"),
                      cienv$jmp$DynamicLossScale(cienv$jnp$array(2^15), 
                                           period = 20L))
      if(plotResults){ 
      makePlots <- function(){
        salience_try <- try({
        message2("Plotting salience maps...")
        nrows_im <- 2
        eval(parse(text = ifelse(dataType == "image", yes = 'pdf(sprintf("%s/CSM_%s.pdf", figuresPath, FigNameAppend),
            width = length(plot_indices)*5+2,height = nrows_im*5)', no = "NULL") ))
        {
          layout(matrix(1:(nrows_im*(1+length(plot_indices))),
                        ncol = 1+length(plot_indices)),
                 width = c(0.5,rep(5,length(plot_indices))),
                 height = rep(5,times=nrows_im)); in_counter <- 0

        # create axis labels in plot positions 1 and 2
        for(text_ in c("Raw Image","Salience Map")){
            if(dataType == "image"){
              par(mar=c(0,0,0,0));
              plot(0, main = "", ylab = "",cex = 0, xlab = "", ylim = c(0,1), xlim = c(0,1), xaxt = "n",yaxt = "n",bty = "n")
              text(0.5,0.5,labels = text_, srt=90,cex=3)
            }
        }

        # generate rest of plot
          message2("Generating salience maps...")
          plot_index_counter <- 0; for(in_ in plot_indices){
            gc(); cienv$py_gc$collect()
            plot_index_counter <- plot_index_counter + 1

            # get data
            setwd(orig_wd); ds_next_in <- GetElementFromTfRecordAtIndices(
                                                    uniqueKeyIndices = which(unique(imageKeysOfUnits) %in% imageKeysOfUnits[in_]),
                                                    filename = file,
                                                    readVideo = useVideoIndicator,
                                                    nObs = length(imageKeysOfUnits) ); setwd(new_wd)
            ds_next_in[[1]] <- cienv$jnp$array( ds_next_in[[1]] )
            if(length(ds_next_in[[1]]$shape) == 3 & dataType == "image"){ ds_next_in[[1]] <- cienv$tf$expand_dims(ds_next_in[[1]], 0L) }
            if(length(ds_next_in[[1]]$shape) == 4 & dataType == "video"){ ds_next_in[[1]] <- cienv$tf$expand_dims(ds_next_in[[1]], 0L) }

            col_ <- ifelse(in_ %in% top_treated, yes = "black", no = "gray")
            in_counter <- in_counter + 1
            long_lat_in_ <- ""; if(  !is.null(lat)  ){ long_lat_in_ <- sprintf("Lat-Lon: %.3f, %.3f", f2n(lat[in_]), f2n(long[in_])) }

            im_orig <- im_ <- InitImageProcessFn( im = cienv$jnp$array(ds_next_in[[1]]), key = cienv$jax$random$key(3L), inference = TRUE )
            XToConcat_values <- cienv$jnp$array(t(X[in_,]),cienv$jnp$float16)
            im_ <- cienv$np$array(cienv$jnp$squeeze(im_,c(0L)))

            # calculate salience map using log probabilities
            # m <- cienv$jmp$cast_to_full(im_orig); x <- cienv$jmp$cast_to_full(XToConcat_values); seed <- cienv$jax$random$key(10L); 
            salience_map <- cienv$np$array(  ImGrad_fxn(
                                        cienv$jmp$cast_to_full(ModelList), cienv$jmp$cast_to_full(ModelList_fixed),
                                        cienv$jmp$cast_to_full(im_orig),
                                        cienv$jmp$cast_to_full(XToConcat_values),
                                        cienv$jnp$expand_dims(cienv$jax$random$key(10L),0L),
                                        StateList, 
                                        MPList )[[1]] )
            if(dataType == "image"){ salience_map <- salience_map[,,1] }
            if(dataType == "video"){ salience_map <- salience_map[,,,1] }

            # do plotting
            orig_scale_im_ <- sapply(1:length(NORM_MEAN), function(band_){
                                       if(dataType == "image"){
                                         im_[,,band_] <- 0.1+im_[,,band_]*NORM_SD[band_] + NORM_MEAN[band_]
                                         return( im_[,,band_] )
                                       }
                                       if(dataType == "video"){
                                         im_[,,,band_] <- 0.1+im_[,,,band_]*NORM_SD[band_] + NORM_MEAN[band_]
                                         return( im_[,,,band_] )
                                       }  }, simplify="array")

            # plot results
            par(mar = (mar_vec <- c(2,1,3,1)))
            if(dataType == "image"){
              dim_ <- dim(orig_scale_im_)
              plotRBG <- !(length(plotBands) < 3 | dim_[length(dim_)] < 3)
              if(!plotRBG){
                causalimages::image2(
                  as.matrix( orig_scale_im_[,,plotBands[1]] ),
                  main = long_lat_in_, cex.main = 2.5, col.main =  col_,
                  xlab = ifelse( plot_index_counter == 1,
                                 yes = ifelse(tagInFigures, yes = figuresTag, no = ""),
                                 no = "")
                )
              }
              if(plotRBG){
                 plot(0, main = long_lat_in_, col.main = col_,
                      ylab = "", xlab = "",
                      cex.main = 4, ylim = c(0,1), xlim = c(0,1),
                      cex = 0, xaxt = "n",yaxt = "n",bty = "n")
                 mtext(side = 1, ifelse( plot_index_counter == 1,
                               yes = ifelse(tagInFigures, yes = figuresTag, no = ""),
                               no = ""), cex = 1)
                 orig_scale_im_raster <- raster::brick(orig_scale_im_[,,plotBands[1:3]])
                 try_ <- try(raster::plotRGB(orig_scale_im_raster, r = 1, g = 2, b = 3,
                                 add = T, main = long_lat_in_, stretch = "lin"), T)
                 if("try-error" %in% class(try_)){ try_ <- try(raster::plotRGB(orig_scale_im_raster, r = 1, g = 2, b = 3, add = T, main = long_lat_in_), T) }
              }

              # plot salience map
              #cienv$optax$global_norm( cienv$eq$filter(ModelList, cienv$eq$is_array)[[1]] )
              try_salience <- try({salience_map[salience_map>0] <- salience_map[salience_map>0] / (0.001+sd(salience_map[salience_map>0]))},T)
              if("try-error" %in% class(try_salience)){
                print( try_salience )
                if(atError == "stop"){ stop() }; if(atError == "debug"){ browser() }
              }
              salience_map <- sign(salience_map)*log(abs(salience_map)+1)
              image2( salience_map, xlab = ifelse(tagInFigures, yes = imageKeysOfUnits[in_], no = ""),cex.lab = 1)
            }
            if(dataType == "video"){
              # plot raw image
              nTimeSteps <- dim(salience_map)[1]
              animation::saveGIF({
              # GIF part 1 --- all in outer time step loop
              for (t_ in 1:nTimeSteps){
              par(mfrow = c(1,2));
              dim_ <- dim(salience_map)
              plotRBG <- !(length(plotBands) < 3 | dim_[length(dim_)] < 3)
              par(mar = margins_gif <- c(5,5,2,1))
              if(!plotRBG){
                par(mar = margins_gif)
                causalimages::image2(
                  as.matrix( orig_scale_im_[t_,,,plotBands[1]] ),
                  main = long_lat_in_, cex.main = 1.5, col.main =  col_,
                  xlab = ifelse( plot_index_counter == 1,
                                 yes = ifelse(tagInFigures, yes = figuresTag, no = ""),
                                 no = "") )
              }
              if(plotRBG){
                plot(0, main = long_lat_in_, col.main = col_,
                     ylab = "", xlab = "",
                     cex.main = 1.5, ylim = c(0,1), xlim = c(0,1),
                     cex = 0, xaxt = "n",yaxt = "n",bty = "n")
                mtext(side = 1, ifelse( plot_index_counter == 1,
                                        yes = ifelse(tagInFigures, yes = figuresTag, no = ""),
                                        no = ""), cex = 1)
                orig_scale_im_raster <- raster::brick(orig_scale_im_[t_,,,plotBands[1:3]])
                try_ <- try(raster::plotRGB(orig_scale_im_raster, r = 1, g = 2, b = 3,
                                            add = T, main = long_lat_in_, stretch = "lin"), T)
                if("try-error" %in% class(try_)){
                  try_ <- try(raster::plotRGB(orig_scale_im_raster, r = 1, g = 2, b = 3,
                                              add = T, main = long_lat_in_), T)
                }
              }

              # GIF part 2
              salience_map[salience_map>0] <- salience_map[salience_map>0] / (0.001+sd(salience_map[salience_map>0]))
              salience_map <- sign(salience_map)*log(abs(salience_map)+1)
              par(mar = margins_gif)
              image2( salience_map[t_,,],
                      main = long_lat_in_, cex.main = 1.5, col.main = "white",
                      #xlab = ifelse(tagInFigures, yes = imageKeysOfUnits[in_], no = ""),
                      cex.lab = 1)
              }}, movie.name = sprintf("%s/CSM_%s_%s.gif", figuresPath, FigNameAppend, plot_index_counter),
                  autobrowse = F, autoplay = F,
                  ani.height = 480*1, ani.width = 480*(1+1))
          }
        }

        eval(parse(text = ifelse(dataType == "image", yes = "dev.off()", no = "NULL") ))
        }},T)
        if('try-error' %in% class(salience_try)){
          print(salience_try);
          if(atError == "stop"){ stop("Problem in salience map computation!")  }
          if(atError == "debug"){ browser() }
        }

        if(optimizeImageRep){
          pdf(sprintf("%s/Loss_%s.pdf", figuresPath,FigNameAppend))
          { 
            par(mar = c(6,5,1,1))
            try(plot(loss_vec, cex = 1.5, cex.lab = 2,
                     xlab = "Iteration", ylab = "Loss"),T);
            try(points(smooth.spline(na.omit(loss_vec)),type="l",lwd=3),T)
            mtext(side = 1, ifelse(tagInFigures, yes = figuresTag, no = ""), 
                  line = 4.5, cex = 1)
          }
          dev.off()
        }

        try({
        message2("Plotting propensity histogram...")
        pdf(sprintf("%s/Hist_%s.pdf", figuresPath, FigNameAppend))
        {
          par(mfrow=c(1,1))
          d0 <- density(prW_est[obsW==0])
          d1 <- density(prW_est[obsW==1])
          plot(d1,lwd=2,xlim = c(-0.1,1.1),ylim =c(0,max(c(d1$y,d0$y),na.rm=T)*1.2),
               cex.axis = 1.2,ylab = "",xaxt = "n",
               xlab = ifelse(tagInFigures, yes = figuresTag, no = ""),
               main = "Density Plots for \n Estimated Pr(T=1 | Confounders)",cex.main = 2)
          axis(1, at = seq(0,1,by = 0.25))
          points(d0,lwd=2,type = "l",col="gray",lty=2)
          text(d0$x[which.max(d0$y)[1]],
               max(d0$y,na.rm=T)*1.1,label = "T = 0",col="gray",cex=2)
          text(d1$x[which.max(d1$y)[1]],
               max(d1$y,na.rm=T)*1.1,label = "T = 1",col="black",cex=2)
        }
        dev.off()
        }, T)
      }
      tryMakePlots_ <- try(makePlots(),TRUE)
      if("try-error" %in% class(tryMakePlots_)){
        warning("Tried but failed to make salience maps...")
      }
      }
    }

    # compute salience for tabular covariates
    SalienceX_se <- SalienceX <- NULL; if(!XisNull){
    if( optimizeImageRep ){
        SalienceX <- c(); samp_counter <- 0
        SalienceX_SampledKeysIndex <- sample(1:length(unique(imageKeysOfUnits)), 25, replace = T)
        # loop approach
        if(FALSE){ 
        for(keyNum_ in SalienceX_SampledKeysIndex){
          samp_counter <- samp_counter + 1
          if(samp_counter %% 5 == 0){  message2(sprintf("Tabular salience iteration %s of %s", samp_counter, 25)) }
          sampIndex_ <- which(imageKeysOfUnits %in% unique(imageKeysOfUnits)[keyNum_])[1]

          # extract data
          setwd(orig_wd); ds_next_in <- GetElementFromTfRecordAtIndices(
                                                           uniqueKeyIndices = keyNum_,
                                                           filename = file,
                                                           readVideo = useVideoIndicator,
                                                           nObs = length(unique(imageKeysOfUnits) ) ); setwd(new_wd)
          ds_next_in[[1]] <- cienv$jnp$array(ds_next_in[[1]])
          if(length(ds_next_in[[1]]$shape) == 3 & dataType == "image"){ ds_next_in[[1]] <- cienv$tf$expand_dims(ds_next_in[[1]], 0L) }
          if(length(ds_next_in[[1]]$shape) == 4 & dataType == "video"){ ds_next_in[[1]] <- cienv$tf$expand_dims(ds_next_in[[1]], 0L) }

          im_ <- InitImageProcessFn( cienv$jnp$array(ds_next_in[[1]]), cienv$jax$random$key(432L), T)
          x_ <- cienv$jnp$array(t(X[sampIndex_,]), cienv$jnp$float16)
          SalienceX_contrib <- cienv$np$array(  dLogProb_dX(  ModelList, ModelList_fixed,
                        cienv$jmp$cast_to_full(im_),
                        cienv$jmp$cast_to_full(x_),
                        cienv$jax$random$split(cienv$jax$random$key( 500L+i ),x_$shape[[1]]),
                        StateList, MPList ) )
          SalienceX <- rbind(SalienceX, SalienceX_contrib)
        }
        }
        
        # vectorized approach
        if(TRUE){
          # Fetch all unique sampled data in one batched call
          setwd(orig_wd)
          unique_indices <- which(
                   unique(imageKeysOfUnits) %in% 
                     (unique_sampled_keys <- unique(imageKeysOfUnits)[SalienceX_SampledKeysIndex])
                  )
          ds_next_in <- GetElementFromTfRecordAtIndices(
            uniqueKeyIndices = unique_indices,
            filename = file,
            readVideo = useVideoIndicator,
            nObs = length(unique(imageKeysOfUnits)),
            return_iterator = FALSE  # Assuming it supports batch return
          )
          setwd(new_wd)
          
          # Process batched data
          ims_ <- InitImageProcessFn(cienv$jnp$array(ds_next_in[[1]]), cienv$jax$random$key(432L), T)
          xs_ <- cienv$jnp$array(X[match(unique(imageKeysOfUnits)[SalienceX_SampledKeysIndex], imageKeysOfUnits), ], 
                                 dtype = cienv$jnp$float16)
          
          # Vectorize gradient computation with vmap
          vmap_dLogProb_dX <- cienv$jax$vmap(dLogProb_dX, in_axes = list(NULL, NULL,
                                                                   0L, 0L, 0L, NULL, NULL))
          SalienceX_contribs <- cienv$np$array(vmap_dLogProb_dX(
            ModelList, ModelList_fixed,
            cienv$jmp$cast_to_full(cienv$jnp$expand_dims(ims_, 1L)),
            cienv$jmp$cast_to_full(cienv$jnp$expand_dims(xs_, 1L)),
            cienv$jax$random$split(cienv$jax$random$key(500L), c(length(unique_sampled_keys),1L)),
            #cienv$jnp$expand_dims(cienv$jax$random$split(cienv$jax$random$key(500L), length(unique_sampled_keys)),1L),
            StateList, MPList
          ))
          
          #plot(colMeans(SalienceX),colMeans(SalienceX_contribs[,1,] )  );abline(a=0,b=1)
          SalienceX <- SalienceX_contribs[,1,] 
        }
        
        SalienceX <- colMeans( SalienceX ); names( SalienceX ) <- colnames(X)
    }
    if( !optimizeImageRep ){
        SalienceX <- myGlmnet_coefs[-1][1:ncol(X)] # drop intercept, then extract variables of interest
        SalienceX_se <- apply(myGlmnet_coefs_mat, 2, sd)[-1][1:ncol(X)] / X_sd 
        SalienceX_se[] <- NA
        if(!is.null(SalienceX)){ names(SalienceX_se) <- colnames(X) }
    } 
      
    # rescale the salience map into original scale (division required by chain rule)
    SalienceX <- SalienceX / X_sd
    }

    postDiffInLat <- preDiffInLat <- NULL
    if(!is.null(lat)){
      preDiffInLat <- colMeans(cbind(long[obsW == 1],lat[obsW == 1])) -
        colMeans(cbind(long[obsW == 0],lat[obsW == 0]))
      postDiffInLat <- colSums(cbind(long[obsW == 1],lat[obsW == 1])*
                                 prop.table(1/prW_est[obsW == 1])) - 
                        colSums(cbind(long[obsW == 0],lat[obsW == 0])*
                                  prop.table(1/prW_est[obsW == 0]))
    }

    # set salience map names
    if(!is.null(SalienceX)){ names(SalienceX) <- colnames(X) }
    rm( InitImageProcessFn )

    message2("Done with image confounding analysis!" ); try(setwd(orig_wd), T)
    return(    list(
      "tauHat_propensityHajek"  = tauHat_propensityHajek,
      "tauHat_propensityHajek_se"  = tauHat_propensityHajek_se,
      "tauHat_diffInMeans"  = mean(obsY[which(obsW==1)],na.rm=T) - mean(obsY[which(obsW==0)],na.rm=T),
      "tauHat_diffInMeans_se"  = c(sqrt(se(obsY[which(obsW==1)])^2 + se(obsY[which(obsW==0)])^2)),
      "SalienceX" = SalienceX,
      "SalienceX_se" = SalienceX_se,
      "prW_est" = prW_est,
      "SGD_loss_vec" = loss_vec,
      "LatitudeAnalysis" = list("preDiffInLat" = preDiffInLat, "postDiffInLat"  = postDiffInLat),
      "ModelEvaluationMetrics" = ModelEvaluationMetrics,
      "AUC" = pROC::roc(obsW[testIndices], prW_est[testIndices])$auc,
      "myGlmnet_coefs" = myGlmnet_coefs,
      "ImageRepresentations_df" = ImageRepresentations_df, 
      "ImageRepresentations_df_transport" = ImageRepresentations_df_transport, 
      "tauHat_propensityHajek_vec" = tauHat_propensityHajek_vec,
      "nTrainableParameters" = nTrainable, # parameters actually trained 
      "nParamsRep" = nParamsRep, # parameters in representation 
      "trainIndices" = trainIndices,
      "testIndices" = testIndices,
      "trainIndices_list" = trainIndices_list,
      "testIndices_list" = testIndices_list 
    ) )
  }
}
