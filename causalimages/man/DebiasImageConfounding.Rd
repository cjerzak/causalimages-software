% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/CausalImage_Confounding.R
\name{DebiasImageConfounding}
\alias{DebiasImageConfounding}
\title{Perform causal estimation under image confounding}
\usage{
DebiasImageConfounding(obsW, obsY, acquireImageFxn, kClust_est, ...)
}
\arguments{
\item{obsW}{A numeric vector where \code{0}'s correspond to control units and \code{1}'s to treated units.}

\item{obsY}{A numeric vector containing observed outcomes.}

\item{X}{(optional) A numeric matrix containing tabular information used if \code{orthogonalize = T}.}

\item{orthogonalize}{(default = \code{F}) A Boolean specifying whether to perform the image decomposition after orthogonalizing with respect to tabular covariates specified in \code{X}.}

\item{imageKeysOfUnits}{(default = \code{1:length(obsY)}) A vector of length \code{length(obsY)} specifying the unique image ID associated with each unit. Samples of \code{imageKeysOfUnits} are fed into \code{acquireImageFxn} to call images into memory.}

\item{kClust_est}{(default = \code{2L}) Integer specifying the number of clusters used in estimation.}

\item{acquireImageRepFxn}{A function specifying how to load images representations associated with \code{imageKeysOfUnits} into memory. For example, if observation \code{3} has a value  of \code{"a34f"} in \code{imageKeysOfUnits}, \code{acquireImageFxn} should extract the image associated with the unique key \code{"a34f"}.
First argument should be image key values and second argument have be \code{training} (in case behavior in training/)}

\item{acquireImageFxn}{(default = \code{acquireImageRepFxn}) Similar to \code{acquireImageRepFxn}; this is a function specifying how to load images associated with \code{imageKeysOfUnits} into memory.}

\item{transportabilityMat}{(optional) A matrix with a column named \code{keys} specifying keys to be used by \code{acquireImageRepFxn} for generating treatment effect predictions for out-of-sample points.}

\item{long, lat}{(optional) Vectors specifying longitude and latitude coordinates for units. Used only for describing highest and lowest probability neighorhood units if specified.}

\item{conda_env}{(default = \code{NULL}) A string specifying a conda environment wherein \code{tensorflow}, \code{tensorflow_probability}, and \code{gc} are installed.}

\item{figuresKey}{(default = \code{""}) A string specifying an identifier that is appended to all figure names.}

\item{figuresPath}{(default = \code{"./"}) A string specifying file path for saved figures made in the analysis.}

\item{simMode}{(default = \code{F}) Should the analysis be performed in comparison with ground truth from simulation?}

\item{plotResults}{(default = \code{T}) Should analysis results be plotted?}

\item{nDepthHidden_conv}{(default = \code{3L}) Hidden depth of convolutional layer.}

\item{nDepthHidden_dense}{(default = \code{0L}) Hidden depth of dense layers. Default of \code{0L} means a single projection layer is performed after the convolutional layer (i.e., no hidden layers are used).}

\item{maxPoolSize}{(default = \code{2L}) Integer specifying the max pooling size used in the convolutional layers.}

\item{strides}{(default = \code{2L}) Integer specifying the strides used in the convolutional layers.=}

\item{yDensity}{(default = \code{normal}) Specifies the density for the outcome. Current options include \code{normal} and \code{lognormal}.}

\item{nMonte_variational}{(default = \code{5L}) An integer specifying how many Monte Carlo iterations to use in the
calculation of the expected likelihood in each training step.}

\item{nMonte_predictive}{(default = \code{20L}) An integer specifying how many Monte Carlo iterations to use in the calculation
of posterior means (e.g., mean cluster probabilities).}

\item{nMonte_salience}{(default = \code{100L}) An integer specifying how many Monte Carlo iterations to use in the calculation
of the salience maps (e.g., image gradients of expected cluster probabilities).}

\item{batchSize}{(default = \code{25L}) Batch size used in SGD optimization.}

\item{kernelSize}{(default = \code{5L}) Dimensions used in convolution kernels.}

\item{nSGD}{(default = \code{400L}) Number of stochastic gradient descent (SGD) iterations.}

\item{nDenseWidth}{(default = \code{32L}) Width of dense projection layers post-convolutions.}

\item{reparameterizationType}{(default = \code{"Flipout"}) Either \code{"Flipout"}, or \code{"Reparameterization"}. Specifies the estimator used in the Bayesian neural components. With \code{"Flipout"}, convolutions are performed via CPU; with `"Reparameterization", they are performed by GPU if available.}

\item{doConvLowerDimProj}{(default = \code{T}) Should we project the \code{nFilters} convolutional feature dimensions down to \code{nDimLowerDimConv} to reduce the number of required parameters.}

\item{nDimLowerDimConv}{(default = \code{3L}) If \code{doConvLowerDimProj = T}, then, in each convolutional layer, we project the \code{nFilters} feature dimensions down to \code{nDimLowerDimConv} to reduce the number of parameters needed.}

\item{nFilters}{(default = \code{32L}) Integer specifying the number of convolutional filters used.}

\item{channelNormalize}{(default = \code{T}) Should channelwise image feature normalization be attempted? Default is \code{T}, as this improves training.}

\item{quiet}{(default = \code{F}) Should we suppress information about progress?}
}
\value{
A list consiting of \itemize{
\item \code{ATE_est} ATE estimate.
\item \code{ATE_se} Standard error estimate for the ATE.
}
}
\description{
\emph{Under construction.}
}
\section{References}{

\itemize{
\item  Connor T. Jerzak, Fredrik Johansson, Adel Daoud. Integrating Earth Observation Data into Causal Inference: Challenges and Opportunities. \emph{ArXiv Preprint}, 2023.
}
}

\examples{
#set seed
set.seed(1)

#Geneate data
x <- rnorm(100)

}
